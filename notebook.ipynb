{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d35af2a",
   "metadata": {},
   "source": [
    "## Testing Optimizer - trial 1 Run \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8dbfc3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, math, random, re, time\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import AdamW\n",
    "from argparse import Namespace\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    GenerationConfig,\n",
    "    set_seed,\n",
    ")\n",
    "\n",
    "# LORA for simple stable run\n",
    "try:\n",
    "    from peft import LoraConfig, get_peft_model, TaskType\n",
    "    PEFT_AVAILABLE = True\n",
    "except Exception:\n",
    "    PEFT_AVAILABLE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4030f8d9",
   "metadata": {},
   "source": [
    "## Configuration Setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "812689cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config = Namespace(\n",
    "   \n",
    "    model_name=os.environ.get(\"MODEL_NAME\", \"gpt2\"),\n",
    "    use_lora=True,\n",
    "    lora_r=8,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.05,\n",
    "\n",
    "\n",
    "    device=(\"cuda\" if torch.cuda.is_available() else \"cpu\" ) or (\"mps\" if torch.mps.is_available() else \"cpu\"),\n",
    "    dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
    "\n",
    "   # rl metrics\n",
    "    G=4,\n",
    "    prompts_per_batch=8,\n",
    "    updates=80,\n",
    "    gen_max_new_tokens=128,\n",
    "    temperature=0.9,\n",
    "    top_p=0.95,\n",
    "\n",
    "    #decoupled clipping\n",
    "    eps_low=0.2,\n",
    "    eps_high=0.28,\n",
    "\n",
    "    #advantage sampling \n",
    "    adv_eps=1e-8,\n",
    "\n",
    "    #length sampling \n",
    "    target_tokens=90,\n",
    "    len_penalty_alpha=0.015,\n",
    "    overlong_mask=True,\n",
    "\n",
    "    #dynamic_Sampling\n",
    "    dynamic_sampling=True,\n",
    "    max_prompt_tries=200,\n",
    "\n",
    "    # optimization\n",
    "    lr=2e-5,\n",
    "    weight_decay=0.0,\n",
    "    grad_clip=1.0,\n",
    "    microbatch=4,\n",
    "    # reproducibility\n",
    "    seed=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ec2173",
   "metadata": {},
   "source": [
    "## Synthetic Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42399d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train=650  val=150\n",
      "You are an educational assistant.\n",
      "Student claims: 2/4 + 3/6 = 5/10.\n",
      "Correct the mistake and provide the right answer.\n",
      "Use this format:\n",
      "Mistake: ...\n",
      "Steps:\n",
      "1) ...\n",
      "2) ...\n",
      "Answer: <fraction>\n",
      " \n",
      "GT: 1/1\n"
     ]
    }
   ],
   "source": [
    "def _gcd(a: int, b: int) -> int:\n",
    "    while b:\n",
    "        a, b = b, a % b\n",
    "    return abs(a)\n",
    "\n",
    "def _simplify(n: int, d: int) -> tuple[int, int]:\n",
    "    g = _gcd(n, d)\n",
    "    return n // g, d // g\n",
    "\n",
    "def _add_frac(a: int, b: int, c: int, d: int) -> tuple[int, int]:\n",
    "    # a/b + c/d = (ad + cb) / (bd)\n",
    "    n = a * d + c * b\n",
    "    den = b * d\n",
    "    return _simplify(n, den)\n",
    "\n",
    "def _build_prompt(a: int, b: int, c: int, d: int) -> str:\n",
    "    # common novice error: add numerators & denominators directly\n",
    "    wrong_n = a + c\n",
    "    wrong_d = b + d\n",
    "\n",
    "    return (\n",
    "        \"You are an educational assistant.\\n\"\n",
    "        f\"Student claims: {a}/{b} + {c}/{d} = {wrong_n}/{wrong_d}.\\n\"\n",
    "        \"Correct the mistake and provide the right answer.\\n\"\n",
    "        \"Use this format:\\n\"\n",
    "        \"Mistake: ...\\n\"\n",
    "        \"Steps:\\n\"\n",
    "        \"1) ...\\n\"\n",
    "        \"2) ...\\n\"\n",
    "        \"Answer: <fraction>\\n\"\n",
    "    )\n",
    "\n",
    "def generate_synthetic_dataset(n: int = 800, seed: int = 0) -> list[dict]:\n",
    "    \"\"\"\n",
    "    Returns a list of examples:\n",
    "      {\n",
    "        \"prompt\": str,\n",
    "        \"answer\": \"n/d\" (simplified),\n",
    "        \"rubric\": [str, ...]  # keywords/signals for shaping rewards\n",
    "      }\n",
    "    \"\"\"\n",
    "    rng = random.Random(seed)\n",
    "    examples: list[dict] = []\n",
    "\n",
    "    for _ in range(n):\n",
    "        b = rng.randint(2, 9)\n",
    "        d = rng.randint(2, 9)\n",
    "        a = rng.randint(1, b - 1)\n",
    "        c = rng.randint(1, d - 1)\n",
    "\n",
    "        n_gt, d_gt = _add_frac(a, b, c, d)\n",
    "        prompt = _build_prompt(a, b, c, d)\n",
    "\n",
    "        examples.append(\n",
    "            {\n",
    "                \"prompt\": prompt,\n",
    "                \"answer\": f\"{n_gt}/{d_gt}\",\n",
    "                \"rubric\": [\"common denominator\", \"add numerators\", \"simplify\"],\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return examples\n",
    "\n",
    "data = generate_synthetic_dataset(n=800, seed=config.seed)  # use your Namespace config\n",
    "random.shuffle(data)\n",
    "\n",
    "train = data[:650]\n",
    "val = data[650:]\n",
    "\n",
    "print(f\"train={len(train)}  val={len(val)}\")\n",
    "print(train[0][\"prompt\"][:220], \"\\nGT:\", train[0][\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a3e175f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ANSWER_RE = re.compile(r\"Answer\\s*:\\s*([0-9]+)\\s*/\\s*([0-9]+)\", re.IGNORECASE)\n",
    "\n",
    "def parse_answer_frac(text: str) -> Optional[Tuple[int,int]]:\n",
    "    m = ANSWER_RE.search(text)\n",
    "    if not m:\n",
    "        return None\n",
    "    n = int(m.group(1))\n",
    "    d = int(m.group(2))\n",
    "    if d == 0:\n",
    "        return None\n",
    "    n,d = simplify(n,d)\n",
    "    return n,d\n",
    "\n",
    "def frac_equal(ans_str: str, pred: Tuple[int,int]) -> bool:\n",
    "    n_gt, d_gt = map(int, ans_str.split(\"/\"))\n",
    "    n_gt, d_gt = simplify(n_gt, d_gt)\n",
    "    return (n_gt, d_gt) == pred\n",
    "\n",
    "def rubric_score(text: str, rubric: List[str]) -> float:\n",
    "    t = text.lower()\n",
    "    s = 0.0\n",
    "    if \"denominator\" in t or \"common\" in t:\n",
    "        s += 0.33\n",
    "    if \"numerator\" in t or \"add\" in t:\n",
    "        s += 0.33\n",
    "    if \"simplif\" in t or \"reduce\" in t:\n",
    "        s += 0.34\n",
    "    return min(1.0, s)\n",
    "\n",
    "def compute_reward(sample_text: str, gt_answer: str, rubric: List[str], gen_token_count: int) -> Dict[str, float]:\n",
    "    parsed = parse_answer_frac(sample_text)\n",
    "    correct = 1.0 if (parsed is not None and frac_equal(gt_answer, parsed)) else 0.0\n",
    "\n",
    "    # base correctness reward (+1 / -1)\n",
    "    base = 1.0 if correct == 1.0 else -1.0\n",
    "\n",
    "    # pedagogy shaping (rubric coverage), only helps if not completely wrong\n",
    "    rub = rubric_score(sample_text, rubric)\n",
    "    shaped = base + (0.4 * rub)  # small bonus for teaching structure\n",
    "\n",
    "    # length shaping: penalize going far beyond target\n",
    "    extra = max(0, gen_token_count - cfg.target_tokens)\n",
    "    shaped -= cfg.len_penalty_alpha * extra\n",
    "\n",
    "    return {\"reward\": shaped, \"correct\": correct, \"rubric\": rub}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c6e8557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 4) Utilities: generation + logprobs on generated tokens\n",
    "# =========================\n",
    "@torch.no_grad()\n",
    "def generate_group(model, prompts: List[str], G: int) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Returns list of dicts for each completion:\n",
    "      {prompt, completion_text, input_ids, attention_mask, gen_token_mask, gen_len, truncated}\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    gen_cfg = GenerationConfig(\n",
    "        max_new_tokens=cfg.gen_max_new_tokens,\n",
    "        do_sample=True,\n",
    "        temperature=cfg.temperature,\n",
    "        top_p=cfg.top_p,\n",
    "        pad_token_id=tokenizer.pad_token_id,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "    )\n",
    "\n",
    "    items = []\n",
    "    for p in prompts:\n",
    "        enc = tokenizer(p, return_tensors=\"pt\", padding=False).to(cfg.device)\n",
    "        prompt_len = enc[\"input_ids\"].shape[1]\n",
    "\n",
    "        # Generate G completions (separately for simplicity)\n",
    "        for _ in range(G):\n",
    "            out = model.generate(**enc, generation_config=gen_cfg)\n",
    "            full_ids = out[0]  # [seq]\n",
    "            gen_ids = full_ids[prompt_len:]\n",
    "            truncated = (len(gen_ids) >= cfg.gen_max_new_tokens)\n",
    "\n",
    "            completion_text = tokenizer.decode(full_ids[prompt_len:], skip_special_tokens=True)\n",
    "            items.append({\n",
    "                \"prompt\": p,\n",
    "                \"completion\": completion_text,\n",
    "                \"full_ids\": full_ids.unsqueeze(0),  # [1, seq]\n",
    "                \"prompt_len\": prompt_len,\n",
    "                \"gen_len\": int(gen_ids.shape[0]),\n",
    "                \"truncated\": bool(truncated),\n",
    "            })\n",
    "    return items\n",
    "\n",
    "def logprobs_on_generated_tokens(model, full_ids: torch.Tensor, prompt_len: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    full_ids: [1, seq]\n",
    "    Returns:\n",
    "      token_logprobs: [T] log p(token_t | <t) for generated tokens only\n",
    "      token_mask:     [T] mask=1 for generated tokens\n",
    "    \"\"\"\n",
    "    # logits for positions 0..seq-2 predicting token 1..seq-1\n",
    "    out = model(full_ids)\n",
    "    logits = out.logits[:, :-1, :]  # [1, seq-1, V]\n",
    "    target = full_ids[:, 1:]        # [1, seq-1]\n",
    "\n",
    "    logp = F.log_softmax(logits, dim=-1)\n",
    "    gathered = torch.gather(logp, dim=-1, index=target.unsqueeze(-1)).squeeze(-1)  # [1, seq-1]\n",
    "\n",
    "    # generated token positions in target space:\n",
    "    # generated tokens begin at position prompt_len in full_ids\n",
    "    # in target indexing (shifted by 1), that corresponds to indices (prompt_len-1 ... seq-2)\n",
    "    start = max(0, prompt_len - 1)\n",
    "    token_logprobs = gathered[0, start:]  # [T]\n",
    "    token_mask = torch.ones_like(token_logprobs, dtype=torch.float32)\n",
    "\n",
    "    return token_logprobs, token_mask"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dapo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
